**Datawarehousing in Google Cloud**

**BigQuery-Datawarehouse**

- Exabyte scale modern Datawarehousing solution from GCP.
  - Relational database(SQL, Schema, Consistency etc)
    - Use SQL-like commands to query massive datasets
  - Traditional (Storage+Compute)+Modern(Realtime+Serverless)
- When we are talking about a Datawarehouse, importing and exporting data (and formats) becomes very important:
  - Load data from a variety of sources, including streaming data
    - Variety of import formats-CSV, JSON, Avro, Parquet, ORC, Datastore Backup
  - Exports to Cloud Storage (long term storage) & Data Studio (Visualization)
    - Formats: CSV/JSON (with Gzip compression), Avro (with deflate or snappy compression)
- Automatically expire data (Configure Table Expiration)
- Query external data sources without storing data in BigQuery
  - Cloud Storage, Cloud SQL, BigTable, Google Drive
  - Use permanent or temporary external tables
  - BigQuery mixes both modern and traditional approach and it can stream and run huge queries.

**BigQuery-Accessing and Querying Data**

- Access Database using:
  - Cloud Console
  - bq command-line tool (NOT gcloud)
  - BigQuery Rest API OR
  - HBase API based libraries (Java,.NET & Python)
- (Remember) BigQuery queries can be expensive as you are running them on large data sets!
- (Best Practice) Estimate BigQuery queries before running:
  - Use UI(console) bq(--dry-run)- Get scanned data volume (estimate)
  - Use Pricing Calculator: Find price for scanning 1 MB data. Calculate cost.

**Partitioning and Clustering BIgQuery Tables- Use Case**

- You pay for BigQuery queries by the amount of data scanned.
  - For Instance, if we scan 20000 rows and the query returns 5000 rows, we need to pay for the 20000 rows.
- Scenario: Imagine a Questions table with millions of rows
  - You want to find all questions asked between a date range (date between 2022-10-02 and 2028-10-02) belonging to a specific category.
    - If you have a single questions table you need to scan all the rows
      - Partitioning- Divide table into multiple segments (example: by date). Partitions between the dates are only scanned.
      - Clustering- Group related data (example: by category)
- Partitioning: Table is divided into segments
  - This process makes it easy to manage and query the data.
  - Improve performance and reduce costs.