*Google PCA Case Studies*

*Link: https://cloud.google.com/certification/guides/professional-cloud-architect*

**Test yourselves as an architect using the case studies**


- Knowledge of Google Cloud Services
- Understanding Problem Domain: AI, ML, Gaming, IOT, Healthcare, Live Streaming
- Download the case studies and spend some time with them
  - Do your analysis and form your opinions

*Cloud Architecture Center: https://cloud.google.com/architecture*

**Case Study: EHR Healthcare - Overview**

- Provide SaaS based electronic health record software for multi-national medical offices, hospitals and insurance providers (exponential growth):
- Current Architecture:
  - Multiple colocation facilities with similar but separate environments (lease on one data center is about to expire)
    - Web-based customer-facing applications running on kubernetes clusters
      - Requirement: Consistent way to manage apps that are container-based.
      - Requirement: Maintain and manage multiple container-based environments
    - Databases: MySQL, MS SQL Server, Redis and MongoDB
    - Legacy file- and API-based integrations with insurance providers
      - Scheduled for replacement over next few years - Will not be moved to Google
      - Requirement: Maintain legacy interfaces to insurance providers (Connectivity to on-premises and cloud)
    - Users are managed via Microsoft Active Directory
    - Monitoring with various open source tools
    - Alert by email (generally ignored)
- Google Cloud will replace their current colocation facilities
- Scalable, resilient platform spanning multiple environments seamlessly
- Facing outages with mis-configured systems, inadequate capacity to manage spikes and inconsistent monitoring practices
- Other requirements:
  - Dynamically scale and provision environments, adapt DRP, Continuous Deployment
    - 99.99% availability, Reduced latency, Regulatory Compliance, Decrease Infrastructure administration costs
  - Centralized visibility and proactive action on system performance and usage
    - Provide consistent logging, log retention, monitoring and alerting capabilities.
  - On board new insurance providers quickly
    - Create interfaces to ingest and process data from new providers
  - Insights and predictions:
    - Make predictions and generate reports on industry trends based on providers data
  - Secure and high-performance connection between on-premises systems and Google Cloud

**Case Study - EHR Healthcare - Discussion**

<table>
<thead>
<tr>
<th>Service</th>
<th>Discussion</th>
</tr>
</thead>
<tbody>
<tr>
<td>Anthos</td>
<td>Run kubernetes clusters anywhere (cloud and on-premises)

Config Mgmt - Central Policies - Kubernetes API, Service Mesh, Access Control

Service Mesh (Dashboards, Logging, Monitoring, Distributed Tracing)

CI/CD - Watch for updates in the Git repository and applies changes to all relevant clusters automatically.</td>
</tr>
<tr>
<td>Cloud Logging, Cloud Monitoring</td>
<td>Alerting Policies for Notifications</td>
</tr>
<tr>
<td>Cloud Logging > (Cloud Storage, BigQuery)</td>
<td>Log Retention</td>
</tr>
<tr>
<td>BigQuery</td>
<td>Make predictions and generate reports on industry trends

Batch: Clud Storage > Dataflow > (BigQuery,...)

Stream: Cloud Pub/Sub > Dataflow > (BigQuery<...)</td>
</tr>
<tr>
<td>Cloud Dedicated Interconnect</td>
<td>Secure and High-Performance connections.</td>
</tr>
<tr>
<td>Cloud CDN</td>
<td>Reduced Latency</td>
</tr>
<tr>
<td>Active Diretory Federation Services (AD FS)</td>
<td>For Single-Sign-On

Google Cloud Directory Sync (Synchronize users and groups from active directory to Cloud Identity)</td>
</tr>
<tr>
<td>Databases</td>
<td>MySQL, MS SQL Server => Cloud SQL

Redis => Memory Store

Mongo DB => (Deploy using Cloud Marketplace or Use Datastore)</td>
</tr>
</tbody>
</table>

**Case Study: Helicopter Racing League - Overview**

- Global Sports League for competitive helicopter racing
  - World championship and several regional league competitions every year
  - Offers paid streaming service for races all over the world with live telemetry and predictions
- Current Architecture:
  - Existing public cloud provider (Public Cloud-First company) hosts:
    - Core of mission critical applications
    - Existing content is stored in an object storage service
    - Race predictions are performed using tensorflow running on VMs.
      - Allow predicting race outcomes but lacks the facility to:
        - Support real-time predictions during races (Requirement)
        - Capacity to process season-long results (Requirement)
  - Video recording and editing is performed at the race tracks
    - Content is encoded and transcoded in the cloud (Using VMs created for each job)
  - Enterprise grade connectivity and local compute provided by truck mounted mobile data centers

**Case Study: Helicopter Racing League - Requirements**

- Migrate existing services to a new platform
  - Expand use of managed AI and ML services to facilitate race predictions:
    - Increase predictive capabilities during and before races:
      - Race Results, Mechanical failures, Crowd Sentiement
      - Enhanced video streams that include predictions of events within the race (Eg: Overtaking)
      - Maintain or increase prediction throughput and accuracy
    - Expose the predictive models to partners
    - Create real-time analytics of viewers consumption patterns and engagement
      - Increase telemetry and create additional insights
      - Measure fan engagement with new predictions
    - Move the serving of real-time and recorded content closer to their users:
      - Reduce latency, enhance global availability and quality of the broadcasts
      - Increase the number of concurrent viewers
    - Create a data mart to enable processing of large volumes of race data
    - Increasing transcoding performance
    - Create a merchandising revenue stream

**Case Study: Helicopter Racing League - Discussion - 1**

<table>
<thead>
<tr>
<th>Service</th>
<th>Discussion</th>
</tr>
</thead>
<tbody>
<tr>
<td>BigQuery + AI Platform</td>
<td>Migrate existing service to a new platform (Managed AI and ML services using Tensorflow)

Create a data mart to enable processing of large volumes of race data (season-long results)

Consider BigQuery ML for realtime predictions.</td>
</tr>
<tr>
<td>Cloud Storage, Cloud CDN</td>
<td>Move the serving of real-time and recorded content closer to their users.</td>
</tr>
<tr>
<td>Apigee</td>
<td>Expose the predictive models to partners</td>
</tr>
<tr>
<td>Cloud Pub/Sub > Cloud Dataflow > Cloud BigQuery</td>
<td>Create real-time analytics of viewer consumption patterns and engagement.</td>
</tr>
<tr>
<td>Transcoder API</td>
<td>Increase transcoding API

Beta- process from/to Cloud Storage</td>
</tr>
<tr>
<td>Video Intelligence API/ Streaming API</td>
<td>Real-time streaming analysis service for live media.

AI Stream Ingestion library allows you to connect to API.

Supports File Streaming, HTTP Live Streaming (HLS), Real time Streaming Protocol (RTSP), Real time Messaging Protocol (RTMP)</td>
</tr>
</tbody>
</table>

**Case Study: Mountrik Games - Overview**

- Online, session-based multiplayer games for mobile platforms
  - Longterm Requirement: Support multiplayer gaming platforms (expand beyond mobile)
- Current Architecture:
  - Migrated on-premises environments to Google Cloud
  - Used Lift-and-Shift VM migration for 5 games
  - Isolated google cloud project for each new game:
    - Legacy games with low traffic consolidated to one project
    - Permissions and network policies managed at folder level

**Case Study: Mountrik Games - Requirements**

- Working on retro-style first-person shooter (FPS) games
  - Hundreds of simultaneous players joining a geo-specific digital arena from multiple platforms and locations
  - Proposed: Run game backend on Google Kubernetes Engine (Rapid Scaling)
    - Google's global load balancer to route to closest regional game arenas
    - Support eventual migration of legacy games to this platform
    - Requirement: Real-time global leaderboard of top players across every active arena
      - Proposed: Use multi-region spanner clusters for near real-time global leaderboards
- Other Requirements:
  - Store game activity logs on structured files for future analysis
  - Use GPU processing to render graphics server-side for multi-platform support
  - Enable advance analytics capabilities
  - Use Cloud-native design principles
    - Multiple regions, Rapid Iteration, Minimize latency and costs, Autoscaling
    - Managed services and Pooled resources

**Case Study: Mountrik Games - Discussion - 1**

<table>
<thead>
<tr>
<th>Service</th>
<th>Discussion</th>
</tr>
</thead>
<tbody>
<tr>
<td>Game Servers(Agones + Kubernetes)</td>
<td>Deliver seamless multiplayer gaming experiences.</td>
</tr>
<tr>
<td>MIGs + VMs + Global Load Balancing + GPUs</td>
<td>If you need a lot of customization</td>
</tr>
<tr>
<td>Cloud Storage</td>
<td>Store game activity logs in structured files for future analysis</td>
</tr>
<tr>
<td>Cloud Spanner</td>
<td>Proposed real-time global leader board

I would prefer Memorystore (Redis)</td>
</tr>
<tr>
<td>Batch-Cloud Storage > Dataflow > BigQuery

Streaming-Pub/Sub > Dataflow > BigQuery</td>
<td>Enable advanced analytics capabilities.

Explore looker for advanced insights.</td>
</tr>
<tr>
<td>Cloud Build, Spinnaker and/or Jenkins</td>
<td>CI/CD</td>
</tr>
<tr>
<td>Cloud Spanner + MemoryStore</td>
<td>Match history database with regional in-memory caching.</td>
</tr>
<tr>
<td>Cloud BigTable</td>
<td>Time Series events</td>
</tr>
<tr>
<td>Cloud Firestore</td>
<td>Player Database</td>
</tr>
<tr>
<td>Cloud BigQuery, AI Platform</td>
<td>Data Warehouse and Intelligence</td>
</tr>
</tbody>
</table>

**Case Study: TerramEarth - Overview**

- Manufactures heavy equipment for the mining and agricultural industries
  - Mission: Build products that make their customers more productive
  - 500 dealers and service centers in 100 countries (Global Audience)
  - 2 million terramearth machines and vehicles with 20% growth year on year.
    - Sensors capture telemetry data from machines and vehicles
    - Subset of critical data transmitted in real time
      - Rest of data collected, compressed and uploded daily when the vehicles return to home base
      - 200 to 500 MB of data per vehicle per day
- Current Architecture
  - Google Cloud
    - Data Aggregation and analysis infrastructure
    - Web frontend for dealers and customers (stock management and analytics)
  - Private data centers
    - Legacy inventory and logistics management systems
    - Two main manufacturing plants send sensor data to private data centers
    - Multiple network interconnects to Google Cloud

**Case Study: TerramEarth - Requirements**

- Current:
  - Provides best in class online fleet management services to customers
    - Improve operations of dealerships
    - Minimize vehicle downtime (Detect failures and rapidly ship parts to dealerships for just-in-time repairs)
  - Autoscaling, DevOps and SRE Elements
    - Improve and standardize tools for app and network monitoring, troubleshooting
    - Mordernize CI/CD pipelines for container based workloads
    - Allow remote developers to be productive
  - Flexible snd Scalable platform for developers to create custom APIs for dealers and partners
    - Create a new abstraction layer for HTTP API access to legacy systems (Enable gradual move to cloud)
    - Self-service portal for internal and partner developers to create new porjects, request resources for data analytics jobs and centrally manage access to the API EndPoints.
  - Use cloud-native solutions for keys and secrets management
    - Use Google Cloud KMS for encryption keys
    - Use Google Cloud Secret Manager for secrets
- 5-year strategic plan:
  - Create a partner ecosystem of new products by enabling access to our data
  - Increase autonomous operation capabilities of vehicles
  - Path to move legacy systems to the cloud

**Case Study: TerramEarth - Discussion - 1**

<table>
<thead>
<tr>
<th>Service</th>
<th>Discussion</th>
</tr>
</thead>
<tbody>
<tr>
<td>IOT Core > Pub Sub > Dataflow > BigQuery > (AI Platform, AutoML, BigQuery ML)</td>
<td>Minimize vehicle downtimes- just-in-time repair

Predictive Maintainence</td>
</tr>
<tr>
<td>Cloud Storage > Dataflow > BigQuery</td>
<td>Batch Process</td>
</tr>
<tr>
<td>Apigee</td>
<td>Flexible and scalable platform for developers to create custom APIs

Create a new abstraction layer for HTTP API access to legacy systems (Enable gradual move to the cloud)

Self-service portal for internal and partner developers.</td>
</tr>
<tr>
<td>Cloud Build, Spinnaker, Jenkins</td>
<td>Modernize CI/CD pipelines for container-based workloads.</td>
</tr>
<tr>
<td>Google Workspace, Virtual Desktops through partners</td>
<td>Allow remote developers to be productive.</td>
</tr>
<tr>
<td>Secret Manager</td>
<td>Use cloud-native solutions for keys and secrets management.</td>
</tr>
<tr>
<td>VPC Flowlogs, Cloud Monitoring, Cloud Logging, etc.</td>
<td>Improve and standardize tools for app and network monitoring, troubleshooting</td>
</tr>
<tr>
<td>Kuberenets-GKE</td>
<td>Container-based workloads-scalable</td>
</tr>
<tr>
<td>Dedicated Interconnect</td>
<td>Networking(High-Data Volume)</td>
</tr>
</tbody>
</table>
