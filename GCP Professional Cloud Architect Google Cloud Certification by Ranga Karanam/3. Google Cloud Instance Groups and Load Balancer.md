**Instance Groups**

- An Instance template is a group of VM instances managed as a single entity. Manage group of similar VM's having similar lifecycle as one unit.
- Instance groups let you organize VM instances or use them in a load-balancing backend service. You can even group existing instance (Creating Unmanaged Instance Groups) or create a group based on an Instance template (Creating MIGs).
There are majorly two types of Instance Groups:

1. Managed Instance Groups(MIG): Identical VMs created using an Instance template (As it is mandatory to use Instance Template over here).
    - *Features*:
        - Auto Scaling (Increase and decrease instances based on the load): Configure auto-scaling to automatically adjust the number of instances based on the load. Here you need to define the minimum and maximum number of instances that can be created inside the MIGs. As moving forward you need to define the autoscaling metrics, where you need to define the CPU Utilization target or Load balancer Utilization target or Any other metric from the stackdriver, here in these metrics you can define the *Cool Down Period* (How long to wait before looking at auto scaling metrics again?) or the *Scale In Controls* (Preventing a sudden drop in number of VM Instances), for Example: Don't scale in by more than 10% or 3 instances in 5 minutes.
        - Auto Healing (Detect application failures using health checks and replace unhealthy instances): Configure a Health Check with initial delay(How long should you wait for your app to initialize before running a health check).
        - Managed Releases
            - Rolling Updates: (Release new version step by step (graudually) to avoid downtime, Update a percentage of instances to the new version at a time)
            - Canary Deployment: Test new version with a group of instances before releasing it across all instances.
        - Maintain Certain number of VMs: If an instance crashes, MIG launches another instance to replace it.
        - Create instances in multiple zones (regional MIGs) (These regional MIGs provide higher availability compared to zonal MIGs)
    - Types of MIGs:
        Stateless: Automatically manage group of VMs that do stateless serving and batch processing.
        Stateful: Automatically manage groups of VMs that have persistent data or configurations (such as databases or legacy applications.)
    Updating a Managed Instance Group:
    - Rolling Update: This is the gradual update of instances in an instance group to the new instance template.
        - Specify a new template:
            - Specify a template for *Canary testing* (This is optional) (For example, configure a template out of which you test 2 instances, Once these two instances are tested you can roll out the update to the other devices too).
            - Specify how you want the update to be done:
                - When should the update happen?
                    - Start the update immediately (Proactive) or when instance group is resized (Opportunistic).
                - How should the update happen?
                    - *Maximum Surge*: The number of instances that are added at any point of time.
                    - *Maximum Unavailable*: The number of instances that can be offline during the time of update.
    - Rolling Restart/Replace: If you want to re-start all the VM instances in the MIGs, without any downtime or you want to replace VMs with new version created with the same template. (Gradual restart or replace of all instances in the group).
        - No Change in the template but replace/restart existing VMs.
        - Configure maximum surge, Maximum Unavailable and what you want to restart or replace the VMs.

    *Practise*:
    - Choose the name for the MIGs and select the instance template you want to use to create the MIGs.
    - Choose from Single Zone or Multiple Zone deployment (Use deafult zone or select the zone you want to use).
    - Now you can define the autoscaling, With the different modes of autoscaling like
        - On: Add and remove instances to and from the group.
        - Scale Out: Only add instances to the group.
        - Off: Do not auto-scale the group.
      Over there you can define the minimum and maximum number of instances for autscaling of the MIGs.
    - Define the autoscaling metrics, Which use metrics to help determine when to scale the group. You can choose from the following metrics:
        - CPU Utilization: The average CPU utilization of the instances in the group. -> You can define the target CPU utilization.
        - HTTP Load Balancing Utilization: The average load balancing utilization of the instances in the group.
        - Cloud Monitoring metric: Any cloud metric that you can query in Cloud Monitoring.
    - Predictive Autoscaling: Use predictive autoscaling to predict future capacity needs based on the historical data. To ensure accuracy, predictive autoscaling will collect data about this managed instance hroup for at least 24 hours before starting to forecast its size.
    - Autoscaling Schedules: You can define the scaling schedule to scale the group up or down at specific times of the day.
    - Cooldown Period: How long to wait before looking at the auto scaling metrics again.
    - Scale in Controls: To set limits for scaling the group, as to don't scale in by more than on Some percentage of VM's over the course of some duration of time.
    - Autoscaling metrics: Here you use the metrics to help determine when to scale the group.
    - Auto Healing: Autohealing re-creates the VM instances if your application cannot be reached by the health check.
    - Health Check: You can define the health check to check the health of the instances in the group.
        - Define the name of the health check.
        - Define the protocol, port and request path.
        - For example: If you are using a HTTP Load balancer use the HTTP protocol and the port number of the HTTP protocol is 80 so define that follwed by the request path "/".
        - You can even get the logs of the health check in Cloud Logging, but this can *Increase the cost*.
        - Health Criteria: This is used to define how the health is determined for the instances in the group, the following are the parameter for the same,
            - Check Interval: Defines how often the health check is performed
            - Timeout: Defined in seconds
            - Unhealthy Threshold: Defines the number of Consecutive failures before the instance is considered unhealthy.
            - Healthy Threshold: Defines the number of Consecutive successes before the instance is considered healthy.
    - Initial Delay: The time required to boot up or the time required by VM to get ready.
    - If you see an exclaimation mark in the health check, it means that it has reached the maximum number of instances that can be created in MIGs.
    - For **Updating the VM* go to the desired Instance Group and click on the *Update VMs* button. There you can,
        - Configure the new instance template. Here you have two options, like let the new template be used for all the instances or you can use the new template on certain number of instances( For Canary Testing like 1 instance or 2 instances) out of total number of instances.
        - Here comes the Update Configuration, where you have option to choose between the automatic and selective updates.
            - Automatic Updates: Here you can define the Temporary additional instances, maximum surge and maximum unavailable instances. In this option you can choose the actions allowed to update the instances(like (Refresh, restart or replace),(Restart or replace),(Refresh or restart), Only Refresh, Only Restart or Only Replace). You can use the checkbox with a check for Keeping the instances names when replacing instances.
            - Selective Updates: Update VMs in this group when they are replaced or restarted, except during the time of auto-healing.
    - For **Restart/Replace VM**, Here you can restart or replace instances. Here are two operations *Restart*(only restart the instances) and *Replace*(Deletes instances and creates new instances with the same template).
        - Restart option: Here you can define the maximum number of unavailable instances(Highest number or percentage of instances that can be unavailable at the same time during an update).
        - Replace option: Here you can define the temporary additional instances(maximum surge in group size to create new instances before deleting ), followed by the maximum number of unavailable instances(Highest number or percentage of instances that can be unavailable at the same time during an update).

2. Unmanaged Instance Groups: VMs with different configuration(VMs with different images used to create, VMs with different hardware) while staying in the same group.
    - *Features*:
        - No Auto Scaling
        - No Auto Healing
        - and other features of Managed Instance Groups
        - Not recommended: unless you need different kinds of VMs in the same group.
    Demo:
    - Choose the location with region and zone.
    - Select the instaces that reside in single zone, VPC Network and Subnet. Choose the VM instance that you want to add to the instance group.
*Location* for the Instance Groups can either be Zonal or Regional. Regional gives you higher availability(**Recommended**).

Notes:

- If you want to release a new version to a MIG without any reduction in capacity, you can set the **--max-unavailable** to 0.
- Unmanaged instance groups doesn't provides you with self-healing and autoscaling features.
- MIGs doesn't contains VMs, with different machine types.
- You can prevent frequent scaling up and down of the VM instances in a MIG by defining the **--cool-down-period**.

**Cloud Load Balancing**

- A Cloud load balancer distributes user traffic across the instances of an application in single region or multiple regions.
  - It is a fully distributed, software defined managed service.
  - Important Features:
    - Health Checks: Route to healthy instances (Recover from failures).
    - Auto Scaling
    - Global load balancing with single anycast IP address(This IP is used to receive traffic from different regions of the world), This also supports internal load balancing.
  - A cloud load balancer enables:
    - High availability: Cloud load balancer distributes traffic across multiple healthy instances.
    - Auto Scaling
    - Resiliency: Cloud load balancer can detect unhealthy instances or down.
- Understanding HTTP, HTTPS, UDP and TCP protocols:
  - Computers use protocol to communicate with each other.
  - Multiple layers and multiple protocols.
  - Network Layer (Layer 3): Transfers bits and bytes. (IP)
    - IP: Internet Protocol: Transfers bytes but at the same time it is unreliable.
  - Transport Layer (Layer 4): Are the bits and bytes transferred properly? (TCP, TLS, UDP)
    - TCP (Transmission Control Protocol): Reliability > Performance
    - TLS (Transport Layer Security): Secure TCP
    - UDP (User Datagram Protocol): Performance > Reliability (Video Streaming, Gaming applications)
  - Application Layer (Layer 7): Make REST api calls and sends emails (HTTP, HTTPS, SMTP)
    - HTTP (Hypertext Transfer Protocol: Stateless Request Response Protocol): Stateless Request Response Cycle Protocol.
    - HTTPS: Secure HTTP
    - SMTP (Simple Mail Transfer protocol): Sends emails.
  - Most applications communicate at application layer.
    - Web apps/REST APIs(HTTP/HTTPS), Email servers(SMTP), File Transfer Protocol(FTP)
    - All these applications use TCP/TLS at network layer(For Reliability)
  - However application which need high performance directly can communicate at transport layer.
    - Gaming applications and live video streaming use UDP(Sacrifice reliability for performance).
  - **Each layer makes use of the layers beneath it.
  - **Most applications talk at application Layer, But some applications talk at network layer directly(for providing high performance).
  - Load balancing is the part of the network services provided by Google Cloud.
  - **Creating a load balancer**
    - There are three types of load balancers provided by the Google Cloud.
      - HTTP(S) Load Balancer: Layer 7 load balancing for HTTP and HTTPS applications. In the configurations you can have HTTP LB, HTTPS LB with options of Internet facing or internal network and Single or Multi Region deployment.
      - TCP Load Balancer: Layer 4 load balancing for applications that rely on TCP/SSL protocols. In the configurations you can have TCP LB, SSL proxy, TCP proxy with options of Internet facing or internal network and Single or Multi Region deployment. For high performance applications like gaming applications, video streaming applications.
      - UDP Load Balancer: Layer 4 load balancing for applications that rely on UDP protocols. In the configurations you can have UDP LB with options of Internet facing or internal network and *Single-Region* deployment.
    - Choose the type of load balancer you want to create and configure the Advance traffic management settings.
    - While creating a load balancer you need to configure three main things:
      - Backend Configuration: Create or select a backend service for incoming traffic. You can add multiple backend services and backend buckets to serve different type of content. Under the new backend you can choose the backend service like Instance group from the list of available backend services. Mention the port number and balancing mode(Utilization or Rate) with the maximum backend utilization and capacity, where you select the rate from balancing mode you can define RPS(Request per second) and the maximum backend capacity. You can also enable the cloud CDN for the backend service, which can provide the caching support for the backend service. Then you need to configure Health Checks for the backend service. You can choose the health checks from the same dropdown and can even create one for your backend service.
                Example: Here we can define the name, with the backend type, the protocol, the port number and the timeout in seconds.
      - Host and path rules: Host and path rules determine how your traffic will be directed. You can direct traffic to a backend service or a storage bucket. Using advanced mode, you can also rewrite user request URLs before directing the traffic or respond to the client with URL redirects. There are two modes available over here
        - Single host and path rule: Under this you can add multiple single hosts with their dedicated backends followed by their path.
        - Advanced host and path rule(URL redirect, URL rewrite)
      - Front-end Configuration: Specify an IP address, port and protocol. This IP address is the frontend IP for your client's requests. While configuring SSL, a certificate must be assigned. The most important configuration which you need to make is in the description page is with Protocol and port, for example for HTTP protocol the port number is 80.
      - Review and Finalise: Under this section you can see and review the configuration of the load balancer you are creating.
- Cloud Balancing Terminologies:
    Usecase:=>
            Client => Cloud Load Balancing => Instances(Compute Engine)

  - Backend: This is the group of endpoints that receive traffic from a Google Cloud Load balancer(For Example:Instance Groups). If you want to have micro-service architecture, you can have multiple backends configured for a single load balancer.
  - Frontend: Specify an IP address, port and protocol. This IP address is the frontend IP for your client's requests. For SSL, a certificate must be assigned.
  - Host and Path rules(For HTTP(s) Load Balancing): Defines the rules redirecting the traffic to different backends.
    - Based on path: in28minutes.com/a vs in28minutes.com/b
    - Based on host: a.in28minutes.com vs b.in28minutes.com
    - Based on HTTP headers: (Authorization header) and methods (GET, POST, PUT, DELETE).
  - Load balancing- SSL/TLS Termination/Offloading:
    - If you're using SSL termination or SSL offloading, then you're working over Layer 7.
    - If you're using TLS termination or TLS offloading, then you're working over Layer 4.
    - Client to Load balancer: Over Internet
      - HTTPS Recommended
    - Load balancer to the VM Instance: Through Google Cloud's internal network.
      - HTTP is Okay. HTTP is preffered over here.
    - SSL/TLS Termination/Offloading:
      - Client to Load balancer: HTTPS/TLS
      - Load balancer to the VM Instance: HTTP/TCP
  - Choosing the type of HTTP Load Balancer:  
    ![Google Cloud Load Balancer](https://cloud.google.com/static/load-balancing/images/choose-lb.svg "Choosing the type of Load Balancer").

  - Cloud Load Balancing Features:
    - External HTTP(s) Load Balancer: This type of loadbalancer deals with Global, External, HTTP or HTTPS traffic. This is the most common type of Proxy(It get requests from the client and they make changes to it while sending some different request to the backend) load balancer used by the Google Cloud. The destination ports of the HTTP on 80 or 8080 and HTTPS on 443.
    - Internal HTTP(s) Load Balancer: This type of loadbalancer deals with Regional, Internal, HTTP or HTTPS traffic. This is the most common type of Proxy(It get requests from the client and they make changes to it while sending some different request to the backend) load balancer used by the Google Cloud. The destination ports of the HTTP on 80 or 8080 and HTTPS on 443.
    - SSL Proxy Load Balancer: This type of loadbalancer deals with Global, External, TCP with SSL offloading traffic. This is the most common type of Proxy(It get requests from the client and they make changes to it while sending some different request to the backend) load balancer used by the Google Cloud. There are big list of ports which are allowed for this type of load balancer.
    - TCP Proxy Load Balancer: This type of loadbalancer deals with Global, External, TCP without SSL offloading traffic. This is the proxy type of load balancer and there are big list of ports which are allowed for this type of load balancer.
    - External Network TCP/UDP Load Balancer: This type of loadbalancer deals with Regional, External, TCP or UDP traffic. This is the Pass-through type of load balancer and here you can use any port number for the load balancer.
    - Internal TCP/UDP Load Balancer: This type of loadbalancer deals with Regional, Internal, TCP or UDP traffic. This is the Pass-through type of load balancer and here you can use any port number for the load balancer.

- Load balancing across MIGs in Multiple Regions:
  - Regional MIG can distribute instances in different zones of a single region.
    - Create multiple regional MIGs in different regions.(In the same project).
  - HTTP(s) load balancing can distribute load to the multiple MIGs behind a single external IP address.
    - User requests are redirected to the nearest region(based on the low latency).
  - Load balancing sends traffic to only healthy instances:
    - If health check fails instances are restarted:
      - (REMEMBER) Ensure that health check from load balancer can reach the instances in an instance group(Firewall Rules).
      - If all backends within a region are unhealthy, traffic is distributed to the healthy backends in other regions.

- Configuring Load Balancer:
  - Backend Service: Group of backends or a bucket.
  - Backend: A managed instance group(MIGs).
  - URL Maps: Route requests to backend services or backend buckets.
    - URL/service-a maps to Backend Service A
    - URL/service-b maps to Backend Service B

- HTTP(s) Load Balancing-1-Multi Regional Microservice (based on compute engine):
  - Backend Service: One backend service for the microservice.
  - Backends: Multiple backends for each microservice MIG in each region.
  - URL Maps: URL /service-a maps to the microservice Backend Service.
  - Global Routing: Route user to nearest instance (Nearest regional MIG)
    - Needs networking premium tier.
      - As in STANDARD tier:
        - Forwarding rules and its external IP address are regional.
        - All backends for a backend service must be in the same region as the forwarding rule.

- HTTP(s) Load Balancing-2-Multi Regional Microservice (based on compute engine):
  - Backend service: One backend service for each of the microservice.
  - Backends: Each microservice can have multiple backend MIGs in different regions.
  - This example has one backend per microservice.
  - URL Maps:
    - URL /service-a => Microservice A Backend Service
    - URL /service-b => Microservice B Backend Service

- HTTPS(s) Load Balancing-3-Microservice Versions (based on compute engine):
  - Backend Service: Craeating a backend service for each microservice version.
  - Backends: Each microservice version can have multiple backend MIGs in different regions.
  - URL Maps:
    - URL /service-b => Microservice B Backend Service
    - URL /service-a/v1 => Microservice A v1 Backend Service
    - URL /service-a/v2 => Microservice A v2 Backend Service
  - Flexible Architecture: With HTTP(s) load balancing, route global requests across multiple versions of multiple microservices.

  Final Quiz:
  - The HTTPS load balancing can load balance between MIGs in different regions.
  - The premium tier of networking is required for global HTTPS load balancing.
  - Six(6) different HTTPS Load balancing backends are required to support one version of each of three different microservices, each wuth two MIGs in two different regions.
